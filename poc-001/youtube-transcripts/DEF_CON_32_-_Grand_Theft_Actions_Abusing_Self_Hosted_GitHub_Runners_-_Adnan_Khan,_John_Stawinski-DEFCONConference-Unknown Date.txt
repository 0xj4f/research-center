all right hello everyone all right let's address the burning question in the room no we did not get access to the source code for Grand Theft Auto 6 nor do we know if the game will ever be released maybe in a following presentation but not today this is Grand Theft actions abusing self-hosted GitHub Runners at scale hello everybody before we get started we read online that as long as we have a disclaimer nobody's allowed to sue us so here we go all vulnerabilities mentioned during this talk have been remediated the views and opinions expressed are solely our own and the content is not endorsed by nor does it represent the views of our employers all right whoa there we go ad on I think we're good to go oh all right if you're wondering about us so my name is Adnan Khan for my day job I work as a security engineer I'm also a security researcher and Bug Bounty Hunter on the side and you can find some of my socials below my name is John stawinsky I'm red team security engineer petoran I also do cicd security research on the side in the last year I've watched avatar the Last air bender three times the animated version and in a past life I was a Collegiate wrestler all right all right so we're going to be talking a lot about self-hosted Runners today so I want to make sure everyone has an background understanding of how GitHub Runners work on one side you have GitHub hosted Runners these are built by GitHub updated frequently and as of writing cover a wide variety of operating systems and architectures the key thing with GitHub hostage Runners as they are is that they are ephemeral meaning they are torn down at the conclusion of each workflow job on the other hand you have self-hosted Runners these are managed and secured entirely by the end user and it's not surprising here that the path of lease resistance when configuring one of these selfhosted Runners is a non-al selfhosted runner that is actually the least secure both gith up hosted and self-hosted Runners work to service GitHub actions workflows that are triggered from repositories on GitHub so why are we here today well all the organizations or and projects that you see on the screen here use or at one point use self-hosted Runners on their public GitHub repositories not only that but they used them in an insecure Manner and over the last 12 months we were able to identify vulnerabilities in these organizations and many more that we can't talk about some of these cases could have led to widespread critical supply chain attacks you may be wondering if we just showed that last slide to flex our cool loones at Devcon and I just want to go on record saying that yeah pretty much but it also raises a bigger question why were we in a position to execute supply chain attacks on all of these companies and the reason behind that is that get up actions provides this broad attack surface that exposes these organizations to compromise especially when they use self-hosted Runners all right so how do we get started with our vulnerability research campaign well it all started all the way back in August of 2022 when I was working on a red team with my former employer I was fairly new to Red teaming at the time and I tripped to Canary and got a kicked out of the client Network maybe that's happened to some of y'all but while trying to get back in we did some social engineering and I found that we could use a GitHub access token that we obtained to execute a workflow and persist on a non-al self-hosted runner inside that client's Network and that got us back in and we reached objective that led to a talk at shukan called Phantom of the PIP P line that was given in January 2023 and the release of the original gate tool around the time that Adan Mason Davis and MOSI were developing gate I joined them on the red team and got was my entry to cicd security so I started using gate to identify get up actions vulnerabilities during red team engagements and then we started diving deeper into get up actions abuse especially around post exploitation and as we were doing our research we were trying to brainstorm ways to blow this up and bring it from internal red team engagement to everybody and AD had an idea that really took it to the next level so one of the little asteris at the end of the shukan presentation was that if you fixed a typo on a public repository that was using a non-al selfhosted runner you could just make a pull request and modify the workflow file and get persistence I demonstrated that vulnerability against GitHub actions Runner images repository which was accepted as a critical vulnerability after outon hacked GI up actions Runner images we started looking at all public repositories and realized that these misconfigurations were everywhere so we decided to team up our first joint operation was breaching Microsoft's perimeter by getting code execution on a domain join machine through Microsoft deep speed uh and then we launched a series of attacks um the next one of which we will cover today all right so at a high level there's three steps to discovering this vulnerability at scale the first step is to search for candidate repositories that might be using a self- holed Runner to do this we use the combination of gith up code search and Source graph code search dorks both have pros and cons so we took used both and duplicated the results to get a nice list of candidate repositories for further analysis to do this use the tool that's open source right now called gate X it uses automated workflow run log analysis to determine if there's a non-al self-hosted runner in use once you have the results you can plan your next step which is essentially can you hack it and can you hack it for some good impact self holer Runner takeover is a a special case of public poison pipeline execution so poison pipeline execution at a high level is anytime you can get your own code executed by a GI up actions workflow you can conduct a poison pipeline attack in the case of self-hosted Runner we'll use this to deploy persistence on the self-hosted runner via pull request and that opens up a ton of lateral movement and privilege escalation paths so these the first two aspects of this diagram are pretty straightforward this last section the get up actions post exploitation is where we focus most of our research all right so it's a tail as old is Unix time itself misconfigurations are Amplified by insecure defaults so the default setting for a poll request approval on the pull request trigger is that it only requires approval for firsttime contributors so if someone has a pull request no matter how trivial merged into the default Branch they won't need approval for workflow executions on their pull requests this is that bad insecure default today we're going to walk through playing with fire which is what we've called our our supply chain attack on the pytorch repository which began by compromising self-hosted Runners this is one of our more complex and more um more intricated attack so we're going to use it as a case study to teach technical ttps of get up actions exploitation and post exploitation as we go all right so what is spy George I'm sure a lot of you already know what it is but it's a machine learning framework originally developed by meta that's been open sourced and it's used by companies around the world like Google Lockheed Martin open Ai and more if someone were to back door pytorch this could allow compromising developers and organizations in that very much RedHot AIML space right now in all in all seriousness probably the hardest part of compromising pytorch was searching through their workflows they had something like over 90 workflows over 15 GitHub secrets and more than five self-hosted Runners on on their public repository and I I vividly remember sitting at my desk I had like three different notebooks out and I was manually pen and paper mapping out the data flow through all of these workflows a lot of which were nested in preparing for this attack so that we could try to figure out the potential impact before we actually started when we confirm that a repository has a self-hosted runner we look at the workflow logs like Onan talked about earlier so here's an example of the py repository and in this screenshot you can see in the work full it has the runner name the runner group name and the Machine name so we see that this is a Jenkins Runner it's a self-hosted runner attached to their public repository in the default group and this is one of the runners that we ended up compromising all right remember that default approval requirement well for certain repositories that are very busy you can often determine that just using contextual analysis and let me tell you pytorch was very busy so what you look for is a pull request submitted by a previous contributor that's from a fork pull request you check that the workflow run associated with it was not approved and that the it ran on the pull request trigger when all these things come together it's very likely that the default approval requirements are in place GitHub warns against attaching self-hosted Runners to public repositories for obvious reasons but you they don't make their documentation and their warnings obvious and you kind of have to go out of your way so part of the reason we think that so many repos publicly use self-hosted Runners is because they don't end up seeing this documentation in this next slide we'll just walk through through what it looks like to register a self-hosted runner and see what documentation you come across as a developer so in my get up repository I'm going to the actions panel I'm trying to register a sosed runner but first i'm going to look through their documentation CU I'm a good developer and I click on these links I don't see anything security related so I click on this other link and we get to a lot of GitHub self-hosted Runner documentation we learn about Auto scaling usage limits uh I think it lists architecture stuff and then every API that the runner is going to use in its lifetime and then way down here at the bottom it talks about self-hosted Runner security and so GitHub does Clearly say they don't recommend using self-hosted GitHub Runners on public repositories and they have other other articles out there too elaborating on elaborating on this but the point we want to drive is it's not obvious so chances are if you're just registering a self-hosted runner to a public repo you're not going to come across this documentation all right the first step was to infiltrate the contributor list this is what is important to take advantage of those default approval settings to infiltrate the contributor list if you've been following our blogs at all we always call the grammar police so the grammar police is me and Adon we show up and we run all of their markdown files through grammarly again fixing a typo here and finding a grammatical error doesn't matter at all to to become a contributor we also could make a legitimate substantial code contribution to the pytorch repository but that's a lot of work so what we do instead is we noticed resolve was in the past tense and it should have been in the present tense so we fixed that for them and we submitted a poll request and a few days later it got merged by the maintainers and then we were now officially contributors which is not a security boundary right and this is the same process we did with all of our exploits all right so this is where the hacking starts so the step phase two was to install command and control on those non-ephemeral self- Holsted Runners attached to pytorch to do this we Lage something we like to call runner on runner in a nutshell what that is is we install another self-hosted runner on their self-hosted Runner this has the benefit of sending all traffic to the same domains and IP addresses that this the original Self holed Runner uses so if there is any EDR monitoring software on that Runner it's very likely that will fly right under the radar oh yeah so remember that default this is where those defaults lead to an actual compromise to do this we just modified our the workflow in our fork and had it just install rc2 the second rep Runner is attached to our private C2 repository so we can task it to execute commands it's essentially a webshell using this webshell we're able to look around the file system and learn about the host and all of this is in preparation for phase three phase three is the most important phase of all of our cicd compromise so the great secret Heist self-host Runner post exploitation is how you go from trivial rce to complete supply chain attack and when we started our research we submitted some reports and we saw some reports where researchers would get code execution on self-hosted Runners and then they'd say hey and by the way you can probably do all these theoretical post exploitation stuff and orgs just just didn't care at all they should care if you're executing code on the runners but it's kind of what they're supposed to do anyway and so they didn't realize the actual impact of these attacks unless you go and demonstrate it so that is what we did all right so to understand how we were able ble to achieve some of this impact I want to make sure everyone understands the magical GitHub token so this is a token that is used by all GitHub actions workflows to authenticate to GitHub for API or git operations and it's an ooth Bearer token that has multiple Scopes some of these Scopes can be read or right and they're configured at the repository organization level or specified within each specific workflow file so it's very important to know that these tokens are only valid for the duration of each job within a workflow as soon as that job concludes the token is no longer valid so to conduct some of the post exploitation attacks here we need to work around this uh limitation so let's see how pytorch at the time used or privileged the giup token okay so this GitHub token has all the right permissions and this means we can we have a lot of options to play with for some of our post exploitation and also this Runner right here is the same one that we now have C2 on so so when a workflow uses the actions checkout step or some other steps the GI up token is stored on the self-hosted runner file system which we have compromis so the problem is that GitHub tokens from Fork PRS only have read permissions uh so if we tried to take the GitHub token from the fork PR we use to actually implant the runners it it's pretty much useless to us so the solution is we persist on the runner and then we capture a token from a future workflow this is the setup we typically see we have the workflow from our Fork PR no access to secrets and a GI up token with only read permissions then we have a workflow from the base repository this repo this workflow does have access to secrets and the GitHub token has right permissions notice how they both execute on the same self-hosted Runner so this is the reason that persistent non-ephemeral self-hosted Runners are so bad right if the runner is ephemeral and we implant it doesn't give us much access Beyond you know secrets on the file system or something like that if it's persistent and long lived then it will execute future workflows so we implant the runner then we wait for future workflows from the base repo to execute on the runner this is why we need to install persistence rather than just showing code execution and then we compromised the GitHub token and any GitHub Secrets used by subsequent workflows so in the in the py chor attack you can see here this was our C2 repository so we were executing code on their selfhosted Runners and we waited for a future workflow to execute from the base repo and then we just printed out the get config file at runtime so this base 64 encoded token is that GitHub token that we were just talking about so we compromised that GitHub token again we could only use it for the duration of the build um but it was it was some of these jobs lasted a long time so we were able to use it for a while all right one of the first things we did after updating the GI up token which had actions right access is we used it to delete the workflow run logs because if we got caught then we likely wouldn't be able to show impact in order for meta triage team to understand the severity of the submission one of the most direct ways to demonstrate impact with a GitHub token is by modifying GitHub releases so GitHub releases is just one way for uh a user to download a release of an application from a repository what uh typically will happen is you can upload GitHub releases so pytorch uploads releases to their GitHub releases page and then if you want to download pytorch one of the ways you can do that is by going to GitHub releases and downloading it there depending on the permissions of the GitHub token it can allow you to modify releases and release assets so you could potentially backd door a release asset upload it and then everyone who downloads and and uses that asset will be running your malicious code we did not want to upload any back door assets we're trying to identify supply chain attacks not actually execute them so instead of tampering with assets we just tampered with the release name so we sent this curl request using the GitHub API uh and it uses the compromise GI up token just to add uh my name to the end of the release so after we sent that request you can see the latest py chch release at the time was now signed by yours truly and all we did here was just take a screenshot and then reverted it right away obviously we didn't want this being seen by a lot of people but this was our POC to show that we could tamper with GI up releases if we wanted to a problem that we've encountered with GitHub release tampering is organizations have came back to us and legitimately said well no one really uses our GitHub releases and obviously that that shouldn't be the case um but to to demonstrate further impact we wanted to look at GitHub Secrets GitHub secrets are the crown jewels of any repo that uses GitHub actions a lot of the times they're overprivileged and they can provide lateral movement opportunities beyond the GitHub repository so we were back to being Charlie from It's Always Sunny and we were searching through all of those py torch workflows again trying to see where GitHub secrets were used and see if we could compromise them here you can see that they're using some personal access tokens which are always super interesting they using AWS Keys uh and and there were a bunch of other Secrets used by the pyus repository and before we go any further I want to quickly recap how we got here so remembering back to the the grammar police we came we fixed a typo that typo got merged that made us a contributor to the repository which was using the default setting so we could execute arbitrary workflows we use that access to execute a workflow that implanted three of their self-hosted Runners then we stole this GitHub token from future a future workflow X executing on that Runner and now we're going to try to use this GitHub token to exfiltrate GitHub Secrets all right one problem that we had to work around is that the workflows that had the giup secrets that we wanted to take didn't actually run on the self-hosted runners that we were now sitting on so the solution here was to use the gith up token to conduct pipeline privilege escalation and get arbitrary code execution within those workflows so we could get those very nice Secrets another problem is get up tokens aren't allowed to modify files in the GitHub workflows directory that seems like a kind of random restriction by GitHub but it's actually implemented a few years ago to prevent these exact attacks so they want to stop attackers from doing what we're trying to do right now and so you can't just make a new Branch modify a workflow to exfiltrate secrets and then you're done the solution here is you need to find a workflow that uses the GitHub Secrets you're interested in that executes code from outside of this GitHub slw workflows directory so this was our our path here if you look back at pyes weekly. workflow at the time you can see it does two interesting things one of them is that it calls thisor update commit has. yo workflow the other is that it uses these update bot tokens and pbot tokens which based on context we were pretty sure were GI up personal access tokens so let's look at update commit has. emo this workflow is still in the restricted workflows directory so we can't modify this workflow with the G token but it calls update commit hases dopy which is in the GitHub scripts directory so it's not in the restricted workflow directory all right so all we need to do now is use the GitHub token to make a new feature branch and modify that script and we know that the workflow that calls it runs on a certain event so we can take advantage of it once the modification that we introduced was quite simple we saved off the tokens that it receiv received via environment variables to files and then we used our public key to encrypt them and print them to the build logs this would prevent any other attackers from getting those Secrets while we were conducting our PC okay so what did we actually do we use the GitHub token to create a new Branch then on the new Branch we added our payload to update commit hases dopy script then we use the get up token to trigger our payload via workflow dispatch event this is because the token had actions right privileges and then we could retrieve the encrypted secrets from the build logs cancel the workflow delete the workflow logs and actually decrypt the secret so at the time when we were doing this operation I was absolutely terrified that I was going to forget to take a screenshot so uh instead of taking screenshots I just screen recorded the whole thing so I have like an 8 Hour screen recording of all this stuff from P torch and I condens some of it into a video on the next slide just showing the the getto personal access token exfiltration so we'll walk youall through that here we have our runon runner C2 and we're going to navigate to our Command output and we're just going to get the base 64 encoded GitHub token this is from a future workflow that was executing on one of the compromised Runners so we're going to Bas 6 C4 decode that token and you can see it's just an authorization header within the GitHub token use the token to clone the repository and then we made a new branch in the in the pytorch repository So within our new Branch we're going to modify that python script that we identified as an injection Point here with my really poor Vim scills I'm going to paste our new payload to exfiltrate those secrets and then once the payload is set we're going to actually Commit This to the repository because the get the token as contents right so we committed to the repo now we're going to use a curl request just to trigger this workflow from our branch which has the injected code in it and then we're looking at the actual pie CHS repository now where we just triggered a workflow and we're going to see two Bas 64 encoded encrypted blobs so we're going to scroll down and we're going to get these blobs which is the out of our commands and then we're going to go to this other ter terminal and decrypt them so first we're just going to base 64 decode them and then we're going to save them to a file and we're going to use our private key locally to actually decrypt them and get the token so once you see some output that starts with GHP uncore those are the personal access tokens and we're going to take them and run them through gate which will do a bunch of automated enumeration using the GitHub apis and then gotta will tell us who the owners are what they have access to and what the potential impact is because if they just had read access to the repository you know there's not a real risk here to pytorch if they have other you know more sensitive privileges then it could be bad so here we're running them through G you can see one of the users is the pytorch update bot user the other is the pytorch bot user and they're both pytorch organization members the token had tokens have repo scope so we can use this now to interact with the Pyro repository directly these are Long Live credentials and they had access to 93 repos within the pytorch organization a lot of which were private and did not have Branch protection so you could have done whatever you wanted to them and there's a lot of P here to supply chain compromise all right that was a lot right okay so what can we do so we have those two tokens so we can use them by themselves to Simply introduce code into the main branch one creates a poll request and have the other want approv and merge it boom supply chain compromise another form would be to back door dependency within the pytorch organization that's used by the primary pytorch repo and that could be a more subtle way to obtain that same uh final impact and finally there's even more clever ways like smuggling malicious code into an in progress feature branch that a developer is working on and then have that merged in so really there's too many paths to count for how this could impact end users of P torch if you want to see even more impact and you're not really into GitHub this section is for you so so if you noticed a few slides ago when we were looking at their secrets we saw that they also had AWS Keys We conducted a very similar attack uh to the one we just showed right where we do that kind of workflow hopping and injection and triggering with the GitHub token we repeated that process to grab their AWS keys and the reason we wanted to do this was if you don't understand GitHub it it can sometimes be hard to even see why code contributions to the main branch of repository could be impactful but everyone understands AWS and aw releases so we grabbed these Keys then we used the AWS CLI to authenticate and we confirmed that we were the P torch bot user so we didn't want to poke around too much but we did some basic AWS S3 LS commands and saw that this user had a lot of privileges we confirmed through the workflow logs that they could actually write to these S3 buckets and one weird thing that we weren't really expecting to see was there were py charts releases in these S3 buckets so at the time honestly I I didn't think too much of it because I was kind of freaked out with the access we had and wanted to submit the report right away I think like we said this was hour 8 or n at this at this point and I just wanted to get the report in so I didn't really pay attention to these releases and then we were rehearsing like a week ago and we were talking and I was like why were these releases in this in these S3 buckets like what system was pulling releases from here so I went to the py CHS website and just going to p.org or p.com whatever it is you can scroll down and you can see when they instruct users to install download install pytorch if you're using pip or whatever you're using this download do uh what is it download. p.org URL so a lot of the releases were coming from this URL so we went to this URL uh in a in a new tab and we're just looking at the request and response headers and sure enough in the headers they confirm that these were actually pulling releases from these S3 buckets um and the the layout of the release assets on on that website were identical to the layout in the S3 bucket so basically with those AWS Keys we could have uploaded our own pytorch releases to these S3 buckets and then anyone who downloads pytorch by following the instructions from the website is going to be downloading and potentially executing our malicious code so this is that kind of solar wind style supply chain attack for anyone that uses pie torch in the future okay that was a lot we just did a lot this is what it looks like put into a nice little red team diagram and if anyone got here late or fell asleep we'll do a quick recap so we started by opening a typo fix PR in the pytorch repository that PR got merged and then we were a contributor so we submitted a malicious poll request that installed our runner on Runner C2 on three different self-hosted GI up Runners from one of these Runners we stole a GitHub token from a future build and we use that to do a bunch of stuff first we just modified that release by updating the release title with my name and reverting then we created a feature branch in the ptch repository and we triggered additional workflows using that workflow disass event injecting through those scripts that were outside of the restricted workflows directory through this process we stole some secrets we stole the P torch spot AWS keys and then we stole two G up personal access tokens used by ptor spot users there were a bunch more secrets in there but we didn't think there was any need for additional demonstration of impact using the AWS Keys we could upload uh new pytorch releases to this S3 bucket obviously we did not do that uh and then using the ghetto personal access tokens we could have modified pyour dependencies we could have used them in conjunction to commit and then approve merges to main uh and done a lot of other bad stuff and so all of this goes to say at the end of the day there were a lot of a lot of supply chain compromis past here which would have affected you know most people using p torch uh both currently and in the future you would think that this amount of demonstration of impact would be enough to convince pytorch to immediately and urgently apply fixes and well we'll just we'll let the disclosure timeline speak for itself so we submitted this issue in August 2023 to meta bug Bounty um a month later meta said there's no update to provide two months later meta said they consider the issue mitigated um I I was suspicious so I went back in and just just executed some codes some uh shell commands on the runners I didn't do the full attack but any anyone could still compromise their Runners any contributor and based on the work for logs and stuff I don't think their configurations were still secure so we responded saying hey the issue is not fully mitigated here's some proof then another two months went by with really no word from meta and we sent a strongly worded email expressing concerns on the remed ation that has been implemented which led to some back and forth and then December 15th meta applied some other fixes which seemed to be sufficient uh and then they offered a call to discuss the Remediation in depth and so we actually ended up meeting with uh two of the pie chorch maintainers and they were very concerned about these issues they were on top of it uh and they also expressed concern at the potential gaps in remediation so I'm not totally sure where the disconnect was but it worried us that pyot torch was potentially vulnerable for this long this attack took a lot of Hands-On keyboard workflow modification uh command and control all that stuff and so it kind of prompted us to say hm is there an easier way to automate a lot of this all right well now there is so with a tool that I've open sourced this week called got X it actually automates that self holster Runner take takeover process so now instead of all that work that you saw John have to do which all you have to do is you fix a typo okay and you become a contributor then you run got X and then one of two things happen Okay you either get a shell and you're on top of the world is hacker man or you learn that approval is required and then you're sad because you didn't get to hack anything so let's walk through a quick video demo of how g x Works to automate this self-hosted Runner takeover process so first I use it to enumerate a runner okay it's non Emeral so now I'm going to go ahead and fix a typo in this test repository here so I go ahead and fix a typo and make that commit so after I make the commit I'm going to go ahead and create a pull request so I check that I fixed the typo and I make a quick P typo fix PR and now that's merged in so after that's merged in with my attacker account I'm going to go ahead and delete the fork so because g x will create a new Fork to throw the payload at the repository so I'm to quickly go ahead and do the web flow to delete a fork and I hit confirm all right now I'm going to run got X so here I've just configured it to deploy a runner on runner on a Linux x86 64-bit Runner so it's going to go ahead and create the the payload within a Guist and ask for confirmation because the next steps are overt so I'm going to type confirm and hit enter so as soon as I do that it's going to create a draft pull request which is going to deploy that runner on Runner payload onto that selfhosted Runner via Fork PR so it's going to take a second because it's now pulling for that Runner to connect to GitHub and then check back into that Repository so as soon as it does that it will drop into a nice and very convenient shell okay now I'm just going to test this with un name- a and when I hit enter what's happening under the hood is that got X is issuing a workflow dispatch event to that workflow in the C2 repository which is going to run code on that our malicious self holed Runner and you can see that output there all right so now you know the techniques and now since I've open source dat you have a tool and another thing I want to point out is that finding cicd misconfigurations and open source repositories can be a very thankless job because you submit a report they fix a bug and you don't even get a cve so there's not really a lot of motivation for people so what I've done with got X is that I've on its Wiki I've created a little Hall of Fame so if you use got X to find a a phone request injection or cell hostage Runner vulnerability in open source project and the maintainers fix it then just make an issue and I'll add you uh your name to the wiki to get some credit just you know make sure it's actually fixed because we don't want the Hall of Fame to be the Hall of OD days as much as some people might like that okay so we showed all the technical ttps we used during our our piech attack but there are a bunch of other stuff we we've used on on other targets and so we want to take this this these next few minutes to honor the Die Hard cicd nerds who are here to learn all the ttps possible so we're going to run through this pretty quickly but all the slides will be up there online so you can check it out after all right so one thing you can do after getting persistence on a runner is a solar win style build compromise so you get persistence and then you just have to modify scripts for the build or source code after it's checked out and once you do that the final build artifacts from that run are going to be poisoned but there's no it's not going to be linked back to the original source code so it's a very stealthy way to conduct a supply chain attack and here's another way that you could take GitHub release asset tampering a little further so if you have that contest right token then all you have to do to tamper with releases on assets is is use the API to delete the old asset and then upload a new one with a post request right on top of it and the indicator of compromise here is just going to be the timestamp when a user is looking at it through the web interface so it's it's not very obvious and if you want to see see a tail of a bug Bounty gone wrong and a program acting in some pretty bad faith uh go check out my blog post on my report to the AAR Network which is a tiny uh polka dot par chain all right another technique you can add to your Arsenal is something called a post checkout hook so what happens when a subsequent workflow that you need to get secrets from or a token from runs only what very infrequently well you need something that can have these qualities it needs you need to be able to extend the build time you also don't want to break how the workflow Works to inform something someone that something's going wrong and you also want to get notified because you don't want to be pressing F5 for 2 weeks well well a quick solution here is to place a script like this into the git hooks directory of the repository and the original Self holed Runner this example here will just take that G get config file encode it and then send it off to your xfill URL and then sleep for 15 minutes so this is going to give you 15 minutes to take advantage of that get up token to perform post exploitation actions all right before we dive into other ttps it's important to remember how selfed run or takeover Falls in within the landscape of broader gith up attack techniques so there's another type of attack called bone requests where you basically get execution within a privileged workflow that's the same thing that happens with run or takeover from there there's different post exploitation techniques you can use so you can steal secrets you could get the actions runtime token which has some interesting attacks with cash poisoning as well as oidc abuse which I think the dock right after uh us and this track actually goes into a lot more detail there so kind of kind of cool and then there's just two many different attacks that talk about there's so many ways to achieve great impact we talked about some of the permissions of the GI up token today but there's a lot of other dangerous permissions out there so some of them don't pose a risk but others like contents right and actions right obviously pose a significant risk so other permissions we've identified as dangerous and actually abused during our attacks are pages right PLL requests right and packages right there's a lot of good documentation online if you want to learn more about what these actually do if you have just accents WR in cont contents right you can create feature branches modify files executed in workflows and then issue dispatches events to seal Secrets if that looks familiar it's because that's exactly what we did during pytorch all right what if you have a workflow that looks like this it runs on workflow dispatch but then uses some of that input in a GitHub script or run step well this lets you do good old 90 style code injection and I'm going to walk you through how this process works and you only need a GI up token actions right to to make this hop so here you can see that the input from the dispatch event as org in repository and within that script step repository is used by get up context expression so that's going to be our injection point there see that Arrow so here's an example payload thrown with a simple request script in Python the first thing here is to close out the script because we don't want a syntax error have it to crash because we still need the code to finish in order for us to get our payload execution the next thing and this is where the actual payload is is a JavaScript injection payload that essentially will pull code from a C2 URL and pipe it to bash so then you can just have arbitrary code there and get execution in that workflow get the token get the secrets um and then from there do more post exploitation if you only have contents right there's still a lot of bad stuff you can do you can modify nonprotected branches a lot of times which actually could end up in releases you can modify releases directly like we did when we signed my name you can modify tags which a lot of times reusable actions are referenced by tags so that could open up some some fun possibilities and then you can also issue repository dispatch events to execute workflows all right here's a really unique way to take advantage of uh contents right all right so one way is if you want to get execution on a workflow that only runs on the push trigger you can add code to that a feature branch that modifies a script that called by that workflow and the next time the developer will push changes now you have arbitrary code execution within the context of that workflow and then you can jump further from there another way is instead of targeting the workflows why not Target the developer so you could modify a unit test within a feature branch that a developer is working on and adds add an info stealer payload so then the when the workflow runs the dev accounts compromised and often in organizations de compromise can be game over another way is if you have these two permissions for the token you can get code modification in the protected default Branch so there's some preconditions here the repository has to have the setting to allow get up actions to approve and merge poll requests there can be at most One reviewer required for that pull request approval Rule and there cannot be any code owner protection rule sets enabled and enforced when all of these are together you can have a attack like this attacker gets the get up token they use their account to create a fork pull request with malicious changes and then they approve that pull request with that capture token and merge that pull request that leads to a good old supply chain compromise now if you're on a runner it's possible to steal the GI up actions runtime token from a future workflow this is where you'll have some attack bats for GI up actions cash poisoning and I have a blog post on my website that goes into the details of that and if there's a organization level run group that shares that also private repositories are using then there's paths to jump to private repositories and other Runner groups and it just kind of blows the those attack bats wide open okay that's the end of some of the more advanced ttps if you're the type of person who likes big mind maps to tell you exactly what to do I made one and I put it on my GitHub a few days ago so you can go check that out obviously this is not comprehensive but if you're trying to get into get act exploitation and you have read or right access to a repo but don't really know what to look for or what to do next check this out it should be able to give you some good guidance in our opinion giup can do a few things better they can increase warnings and awareness so if you try to attach a cell phosa Runner to a public repo it'd be great if there were Big Red Letters saying be careful this is dangerous they can also improve their secure defaults like we talked about with the workflow approval requirements and then they could Implement granular approval requirements so that maintainers don't need to select between three options all of which have broad privileges and probably will hurt developer workflows one way or the other if you're trying to defend your organization from these attacks start with the easy stuff please change this radio button so that you require approval for all outside collaborators we we use the GitHub token extensively and almost all of our attacks set it to read only that will stop a lot of post exploitation opportunities and then use and force your devs to use fine grain personal access tokens we like we hate discovering fine grain tokens on red team engagements because they only give you access to one repository if we find a personal access token that's classic we can do a lot of stuff if it's fine grain sometimes that's the end of the road all right there's also ways to secure yourself more by making sure that your self holed Runners are ephemeral so GitHub maintains something called actions Runner controller which allows you to automatically spin up and spin down selfhosted Runners using kubernetes also a lot of cloud providers have autoscaling groups that can be linked with selfhosted Runners and have that also be done on automatically and finally there's a lot of third parties that offer TurnKey drop in replacements for GitHub Runners that are also ephemeral if you don't want to use just to get up hosted Runners and one thing that's important to remember here is that ephemeral means you the environment that the runner is in also has to be ephemeral so if there's an ephemeral Runner but it's using a non-ephemeral file share then attacker can simply jump to other workflows by Saving certain files off so it's important to really consider the entirety of that that environment when it comes to build agent security all right so another way is by using github's feature for Runner group pinning so GitHub has a feature where if you have a work a runner group you can actually pin it to a specific workflow and or even a specific sha or reference of a workflow so with this you have a lot of different options to restrict which workflows can even use the runner and all of this has the ultimate effect of protecting your most privileged runners we want to end our talk today by emphasizing that this talk and this research is not about pip torch so we have some some key takeaways here if you've been zoning out lock in for this last slide but what what we did to pytorch we've been able to do to a lot of advanced mature organizations because of this lack of awareness around cicd agent security so I think we' submitted over 20 highend critical bug Bounty submissions among them were critical vulnerabilities in GI up actions Microsoft pytorch tensorflow AAR uh Hydro GX bite dance and a lot more that we're not allowed to talk about additionally if you think that public cic security is bad internal cicd security is a nightmare almost uh not every red team engagement I've been on but a lot of red team engagements were able to get access to a cicd platform and then escalate Privileges and use it to reach objective it's almost become the new adcs for us where internally everyone's vulnerable and compromising these cicd platforms can give you uh extensive privileges finally what we need everyone to do is go learn about these attacks to protect your or from compromise the main issue we see is this just this lack of awareness so if if devs Architects execs and everyone is learning about these attacks they'll be able to implement controls that hopefully protect their organization from the next critical supply chain attack all right the moral of the story here is learn about this stuff and don't let this be you all right all right so we want to start off by thanking all of the bug Bounty triage teams that handled some of the reports and handled them well and applied solid mitigations to their products we'd like to thank everyone who showed out today thank you so much for watching us and helping us raise awareness and for everyone watching online thank you uh we'd like to thank Defcon for giving us this platform we wanted to speak here for a long time so this has been really fun uh please we don't have time for questions but come find us after if you want to talk more thank you everybody